{"cells":[{"cell_type":"code","execution_count":null,"id":"e726ecea-fcb8-43cd-a112-f2fb4563d52d","metadata":{"id":"e726ecea-fcb8-43cd-a112-f2fb4563d52d","outputId":"f59ac89b-902d-4be9-afac-b5fcdc6ee272"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tqdm in c:\\users\\zm\\anaconda3\\lib\\site-packages (4.65.0)\n","Requirement already satisfied: colorama in c:\\users\\zm\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n","Requirement already satisfied: ollama in c:\\users\\zm\\anaconda3\\lib\\site-packages (0.1.6)\n","Requirement already satisfied: httpx<0.26.0,>=0.25.2 in c:\\users\\zm\\anaconda3\\lib\\site-packages (from ollama) (0.25.2)\n","Requirement already satisfied: anyio in c:\\users\\zm\\anaconda3\\lib\\site-packages (from httpx<0.26.0,>=0.25.2->ollama) (3.5.0)\n","Requirement already satisfied: certifi in c:\\users\\zm\\anaconda3\\lib\\site-packages (from httpx<0.26.0,>=0.25.2->ollama) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in c:\\users\\zm\\anaconda3\\lib\\site-packages (from httpx<0.26.0,>=0.25.2->ollama) (1.0.4)\n","Requirement already satisfied: idna in c:\\users\\zm\\anaconda3\\lib\\site-packages (from httpx<0.26.0,>=0.25.2->ollama) (3.4)\n","Requirement already satisfied: sniffio in c:\\users\\zm\\anaconda3\\lib\\site-packages (from httpx<0.26.0,>=0.25.2->ollama) (1.3.0)\n","Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\zm\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<0.26.0,>=0.25.2->ollama) (0.14.0)\n","C:\\Users\\zm\\Desktop\\ollama\\BBQ\n"]}],"source":["!pip install tqdm\n","!pip install ollama\n","\n","import ollama\n","\n","ollama.pull('llama3:text')\n","\n","client = ollama.Client()\n","\n","#update with your file path\n","%cd C:\\Users\\zm\\Desktop\\ollama\\BBQ"]},{"cell_type":"code","execution_count":null,"id":"b4fc702a-b98c-49ed-8af8-19491e574450","metadata":{"scrolled":true,"id":"b4fc702a-b98c-49ed-8af8-19491e574450","outputId":"9a621c85-04e8-40e3-c906-98d85d862161","colab":{"referenced_widgets":["3826609a1c094782a40d80afabbfec72"]}},"outputs":[{"name":"stdout","output_type":"stream","text":["Generating responses for file: C:\\Users\\zm\\Desktop\\ollama\\BBQ\\Age.jsonl\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3826609a1c094782a40d80afabbfec72","version_major":2,"version_minor":0},"text/plain":["Generating responses:   0%|          | 0/1000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n","Generation timed out. Retrying...\n"]}],"source":["import os\n","import json\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","import time\n","import threading\n","\n","def generate_response_with_ollama(prompt, timeout=5):\n","    # Container for storing the response\n","    response_container = []\n","\n","    # Function to run in a thread\n","    def target():\n","        try:\n","            response = ollama.generate(model='llama3:text', prompt=prompt)\n","            response_container.append(response)\n","        except Exception as e:\n","            print(f\"Error generating response: {e}\")\n","            response_container.append(None)\n","\n","    # Start the thread\n","    thread = threading.Thread(target=target)\n","    thread.start()\n","\n","    # Wait for the thread to complete or timeout\n","    thread.join(timeout)\n","    if thread.is_alive():\n","        print(\"Generation timed out. Retrying...\")\n","        thread.join()  # Ensure thread is not left hanging\n","        return generate_response_with_ollama(prompt, timeout)  # Retry on timeout\n","    else:\n","        return response_container[0] if response_container else None\n","\n","def generate_responses(directory_path):\n","    responses = []\n","    prompts = []\n","\n","    for filename in os.listdir(directory_path):\n","        if filename.endswith('.jsonl'):\n","            file_path = os.path.join(directory_path, filename)\n","            print(f\"Generating responses for file: {file_path}\")\n","\n","            with open(file_path, 'r') as file:\n","                for line in file:\n","                    json_obj = json.loads(line)\n","                    context = json_obj.get('context', '')\n","                    question = json_obj.get('question', '')\n","                    ans0 = json_obj.get('ans0', '')\n","                    ans1 = json_obj.get('ans1', '')\n","                    ans2 = json_obj.get('ans2', '')\n","                    prompt = context + ' ' + question + ' ' + '(A) ' + ans0 + ' or ' + '(B) ' + ans1 + ' or ' + '(C) ' + ans2 + \". Limit your answer to only tell me whether A, B or C is correct without any further explanation. Limit output to one of the options and only 1 character.\"\n","                    prompts.append(prompt)\n","\n","            for prompt in tqdm(prompts[:1000], desc='Generating responses'):\n","                response = generate_response_with_ollama(prompt)\n","                responses.append(response)\n","                time.sleep(1)  # Throttling to avoid hitting rate limits or overloading the system\n","\n","    responses_df = pd.DataFrame({'prompt': prompts, 'response': responses})\n","    responses_df.to_csv('responses_temp.csv', index=False)\n","    print(\"All responses generated and saved temporarily.\")\n","#update with your file path\n","generate_responses('C:\\\\Users\\\\zm\\\\Desktop\\\\ollama\\\\BBQ')\n"]},{"cell_type":"code","execution_count":null,"id":"67027c7c-0ed3-481e-9ad7-5649fe434455","metadata":{"id":"67027c7c-0ed3-481e-9ad7-5649fe434455"},"outputs":[],"source":["import pandas as pd\n","\n","def update_jsonl_with_responses(directory_path):\n","    responses_df = pd.read_csv('responses_temp.csv')\n","\n","    for filename in os.listdir(directory_path):\n","        if filename.endswith('.jsonl'):\n","            file_path = os.path.join(directory_path, filename)\n","            jsonl_df = pd.read_json(file_path, lines=True)\n","            jsonl_df = jsonl_df.head(len(responses_df))  # Ensure the lengths match\n","\n","            # Assuming responses_df and jsonl_df are in the same order\n","            jsonl_df['response'] = responses_df['response']\n","\n","            updated_file_path = file_path.replace('.jsonl', '_updated.jsonl')\n","            jsonl_df.to_json(updated_file_path, orient='records', lines=True)\n","            print(f\"Updated file saved for: {filename}\")\n","#update with your file path\n","update_jsonl_with_responses('C:\\\\Users\\\\zm\\\\Desktop\\\\ollama\\\\BBQ')\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}